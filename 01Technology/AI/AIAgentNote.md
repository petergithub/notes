# AI Agent

[What are AI agents? Definition, examples, and types | Google Cloud](https://cloud.google.com/discover/what-are-ai-agents)

## AI Agent 基础设施

[AI Agent 基础设施](https://mp.weixin.qq.com/s/xp1f1BistZxy9rES3We3sA)

AI Agent是利用人工智能技术以实现特定目标并为用户完成任务的软件系统。它们展现出推理、规划、记忆以及一定程度的自主性，能够进行决策、学习和适应环境 。这些Agent能够同时处理包括文本、语音、视频、音频和代码在内的多模态信息，并具备对话、推理、学习和决策的能力 。

**AI Agent的核心功能组件**
AI Agent的强大功能源于其内部多个核心组件的协同工作。这些组件共同构成了Agent的感知、思考、决策和行动能力。

1. 大脑：核心LLM、推理与规划
2. 感知与行动模块：与环境交互
   1. 环境感知模块：感知模块负载把需要的上下文、环境信息召回，传递给大模型。在感知模块中，语义搜索、NL2SQL等能力是基础，这些模块的能力把LLM感知环境的需求转换为具体的获取数据的操作
   2. 行动模块 ：负责执行Agent的决策，这可能包括调用API、与外部工具交互、生成文本或代码，甚至在机器人技术中执行物理动作
3. Memory：学习与维护上下文
   1. 短期记忆 (Short-Term Memory)
   2. 长期记忆 (Long-Term Memory)
   3. 分层记忆系统：如工作记忆、短期记忆和长期记忆的组合，可以提高检索速度和上下文保真度 。
4. 工具集成与使用：扩展Agent能力
   1. 交互协议层: MCP, A2A
   2. 工具发现和整合
   3. 沙箱：沙箱是保障工具安全运行的前提
5. 路由器/控制器：管理复杂工作流
   1. 涉及多个工具或子Agent的多步骤任务时，一个有效的控制器对于协调这些组件变得至关重要

**Agent系统运维基础设施**
包括LLM API网关、缓存策略以及安全的工具执行环境。

1. LLM API网关：统一访问、安全与可观测性
2. LLM响应的缓存策略：性能与成本优化
   1. 精确键缓存 (Exact Key Caching)
   2. 语义缓存 (Semantic Caching)
3. 安全的工具执行环境：沙箱与凭证管理

**Agent编排与协作**
Agent的智能不仅仅体现在其个体能力上，更在于它们如何组织自己的“思维”过程以及如何与其他Agent或系统进行协作。

- 思维链 (Chain-of-Thought, CoT)：将任务分解为更小的步骤，以逐步求解。非常适合需要逻辑或多步骤推理的任务 。它帮助模型分解任务，使其思考过程更易于理解 。
- ReAct (Reasoning and Acting, 推理与行动)：将CoT推理与外部工具使用相结合 。它涉及一个“思考 (Thought) -> 行动 (Action) -> 观察 (Observation)”的循环 。这使得Agent能够根据新信息或前一步骤的结果动态调整其方法 ，从而增强LLM在Agent工作流中处理复杂任务和决策的能力 。
- Reflexion (反思)：利用反馈循环，使LLM能够反思过去的输出并迭代地改进其性能 。这种模式非常适用于需要多次尝试进行优化和复杂推理的任务

**开源Agent框架**
开源Agent框架旨在通过提供预构建的组件和抽象来简化Agent的开发过程

- LangChain：采用模块化架构，适用于具有直接工作流的简单Agent。它支持向量数据库和记忆功能，其LangSmith平台可用于调试和监控 。然而，一些开发者认为它过度抽象，难以使用，甚至有些过度工程化 。
- LangGraph：作为LangChain生态系统的一部分，LangGraph采用图架构（节点代表任务/动作，边代表转换），并包含一个状态组件来维护任务列表。它非常适合周期性、条件性或非线性工作流 。LangGraph提供了比其他框架更高的可控性，并有意保持其底层和集成无关性 。
- AutoGen：由微软推出的多Agent AI框架，采用分层架构（核心层、AgentChat层、扩展层）。它支持异步消息传递和对话式AI助手的构建，并提供AutoGen Bench和AutoGen Studio用于开发和基准测试 。
- CrewAI：一个用于多Agent解决方案的编排框架，采用基于角色的架构（Agent、任务、流程——顺序或分层）。它底层使用了LangChain ，但本身是一个独立的框架 。其局限性在于目前主要支持顺序编排，并且可能产生不完整的输出 。

## 问题

面了个半调子后端转AI Agent方向 真的无语
后端程序员转AI Agent本是优势组合——工程架构、分布式处理能力都是落地关键。但近期面试中，多数候选人的表现却差距明显，暴露出转岗的共性误区。

📌 架构认知浮于表面，核心逻辑空白
候选人多能复述“感知-决策-执行”架构，可追问“短期与长期记忆如何联动”“工具调用冲突怎么调度”时，便难以给出有效方案。实则这些问题可类比后端“缓存-数据库联动”“分布式任务优先级控制”，但多数人未建立知识迁移意识，架构认知仅停留在名词层面。

📌 项目止于Demo级，工程属性缺失
“用LangChain做过AI助手”是高频回答，但深究便露馅：API超时无重试机制、“整理纪要并发邮件”的任务拆分逻辑混乱、无与纯大模型的效果对比数据。后端擅长的容错设计、链路监控等能力，未在Agent项目中体现，项目仅完成工具调用的表层拼接。

📌 工程思维未迁移，落地能力薄弱
谈及1000用户并发，回答多为“直接扩容”，忽视Agent上下文状态管理与资源复用；提到上下文窗口不足，仅说“截断处理”，未考虑记忆丢失对决策的影响。更有候选人在多Agent协作项目中省略权限校验，违背后端安全开发基线。

📌 后端转岗的核心成长路径
1. 补AI基础：聚焦大模型函数调用、提示词工程，将其视为“AI版接口开发”，建立技术关联；
2. 深研Agent核心：用后端逻辑理解记忆机制（短期=缓存、长期=持久化存储）、任务规划（类比分布式调度）；
3. 小项目练落地：从“PDF解析+问答”切入，嵌入重试、日志监控等后端实践；
4. 融合能力：将并发控制、权限管理等后端技能，迁移至多Agent协作场景。
后端转AI Agent的关键，是让工程优势与AI认知形成合力。避开概念堆砌误区，才能真正实现高效转岗。


很多人以为会调个OpenAI的接口、跑通Demo就是AI开发了，实际上连AI开发的门槛都没摸到

总结 4 类典型“送命题”

1. 概念背得滚瓜烂熟，落地细节一问三不知

核心痛点：把LangChain文档背得挺熟，真到了业务场景就露馅。

具体反例：问他RAG，自信说“这我熟”。深问一句：“你的文档切片策略是什么？怎么解决长下文截断丢失语义的问题？” 沉默..只跑过官方Demo，没处理过真实脏数据。

2. 只有Demo思维，没有工程思维

核心痛点：做出来的东西是个玩具，根本没法上线。

反例： 做的Agent演示效果不错，我问他：“如果并发上来怎么控制Token成本？API响应超时怎么做降级熔断？模型出现幻觉怎么做后处理验证？” 他一脸茫然，仿佛这些是运维的事。但在开发里，稳定性比Feature更难做。

3. 把Prompt Engineering当成“跟机器人聊天”

核心痛点： 以为会打字就会写Prompt，完全不懂结构化指令。

反例：设计处理复杂任务的Prompt，他用大白话跟AI谈心，不懂什么是CoT、Few-Shot，更不懂怎么约束输出格式。结果就是模型输出极不稳定，还要靠后端代码写一堆正则去修补。

4. 拿着锤子找钉子，为了AI而AI

核心痛点：技术选型由于缺乏场景感，导致方案极其低效。

反例：字符串提取，明明写个正则表达式0.01秒就能搞定，他非要调用GPT-4去处理，他说“这样更智能”。这不叫智能，这叫烧钱且低效。

面试官的真实感慨

现在的市场上不缺会调用API的程序员，缺的是真正理解大模型边界、能把‘概率性模型’驯服成‘确定性产品’的工程师

转型人助力按这个梯度去恶补：

1、脱离API调包侠

别光看LangChain，去手写一个简单的RAG流程。搞懂Embedding、向量数据库到底是怎么存、怎么查的。

2、精通提示词工程

掌握CoT、ReAct框架，学会让模型按你的逻辑去思考，用Prompt解决模型变笨的问题。

3、掌握Agent编排架构

学习Multi-Agent协作，理解规划、记忆、工具使用这三大件怎么在代码层流转。

4、死磕落地与评测

高薪分水岭。建立一套自动化评测集，关注Tracing，懂得在模型智商和推理成本之间做Trade-off。
