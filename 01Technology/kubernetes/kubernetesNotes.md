# kubernetesNotes

## Recent

batch delete `kdelp $(kgp -l | grep Evicted | awk '{print $1}')`
kubelet summary API `http://localhost:8001/api/v1/nodes/node-name/proxy/stats/summary`

### è·å–ä¿¡æ¯ æ’æŸ¥é—®é¢˜

kubectl get events -A -o custom-columns=FirstSeen:.firstTimestamp,LastSeen:.lastTimestamp,Count:.count,From:.source.component,Type:.type,Reason:.reason,Message:.message |less
kubectl get events -o custom-columns=Created:.metadata.creationTimestamp,FirstSeen:.firstTimestamp,LastSeen:.lastTimestamp,Count:.count,From:.source.component,Type:.type,Reason:.reason,Message:.message --field-selector involvedObject.kind=Pod,involvedObject.name=mysql-test-78b7567ccc-b96kb

kubectl get events -o custom-columns=Created:.metadata.creationTimestamp,FirstSeen:.firstTimestamp,LastSeen:.lastTimestamp,Count:.count,From:.source.component,Type:.type,Reason:.reason,Message:.message --field-selector involvedObject.kind=Pod --sort-by=.metadata.creationTimestamp |less
kubectl get events -o custom-columns=Created:.metadata.creationTimestamp,FirstSeen:.firstTimestamp,LastSeen:.lastTimestamp,Count:.count,From:.source.component,Type:.type,Reason:.reason,Message:.message --sort-by=.metadata.creationTimestamp |less

kubectl get pods -A -o=jsonpath='{range .items[*]}{.spec.containers[].resources.requests.memory}{"\t"}{.status.hostIP}{"\t"}{.metadata.name}{"\n"}{end}' | grep 145

## Concept

### [Requests and limits](https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#meaning-of-memory)

Meaning of memoryï¼ŒMiè¡¨ç¤ºï¼ˆ1Mi=1024x1024ï¼‰,Mè¡¨ç¤ºï¼ˆ1M=1000x1000ï¼‰ï¼ˆå…¶å®ƒå•ä½ç±»æ¨ï¼Œ å¦‚Ki/K Gi/Gï¼‰
For example, the following represent roughly the same value: `128974848, 129e6, 129M, 123Mi`
1 (byte), 1k (kilobyte) or 1Ki (kibibyte), 1M (megabyte) or 1Mi (mebibyte)

Meaning of CPU:
The expression 0.1 is equivalent to the expression 100m, which can be read as "one hundred millicpu". Some people say "one hundred millicores", and this is understood to mean the same thing. A request with a decimal point, like 0.1, is converted to 100m by the API, and precision finer than 1m is not allowed. For this reason, the form 100m might be preferred.
`0.1 = 100m`

### Common

`k logs -f --tail=10 pod-name`
  `-o custom-columns` option an
  `--sort-by=<jsonpath_exp>` sort the resource list, `--sort-by=.metadata.name`
[Resource types](https://kubernetes.io/docs/reference/kubectl/overview/#resource-types)

`kubectl get pods -o custom-columns=NAME:.metadata.name,CPU:.spec.containers`
[JSONPath Support](https://kubernetes.io/docs/reference/kubectl/jsonpath/)
`kubectl get pods -A -o=jsonpath='{range .items[*]}{.status.hostIP}{"\t"}{.spec.containers[].resources.requests.cpu}{"\t"}{.spec.containers[].resources.requests.memory}{"\t"}{.metadata.name}{"\n"}{end}' --sort-by='.status.hostIP'`

### Debug

æ’æŸ¥é—®é¢˜
`kubectl get events`
`kubectl -n namespace top pods`
`kubectl get events -o custom-columns=Created:.metadata.creationTimestamp,FirstSeen:.firstTimestamp,LastSeen:.lastTimestamp,Count:.count,From:.source.component,Type:.type,Reason:.reason,Message:.message --field-selector involvedObject.kind=Pod,involvedObject.name=mysql-test-78b7567ccc-b96kb`
`kubectl get events --sort-by=.metadata.creationTimestamp`
`kubectl get events -o yaml|less`

jsonpath æŸ¥è¯¢ç”³è¯·çš„å†…å­˜
`kubectl get pods -A -o=jsonpath='{range .items[*]}{.spec.containers[].resources.requests.memory}{"\t"}{.status.hostIP}{"\t"}{.metadata.name}{"\n"}{end}' | grep 145`

go-template `kubectl get pods -o go-template='{{range .items}}{{.status.podIP}}{{"\n"}}{{end}}'`

`kubectl cluster-info dump`

### Command

[kubectl Overview](https://jamesdefabia.github.io/docs/user-guide/kubectl-overview/)

`kubectl help get`

`minikube start` Starting a Minikube virtual machine
`kubectl explain pod` kubectl explain to discover possible API object fields
`kubectl explain pod.spec` drill deeper to find out more about each attribute
`kubectl api-resources` Print the supported API resources on the server

`kubectl cluster-info` Displaying cluster information
`kubectl get nodes/pods/secrets/services/deployment`
    `-o wide` request additional columns to display
    `-o yaml` get a YAML descriptor of an existing pod
    `-o json`
    `--show-labels`
    `-L, --label-columns=[]` switch and have each displayed in its own column `-L creation_method,env`
    `-l, --selector=''`
    `-A, --all-namespaces=false` If present, list the requested object(s) across all namespaces
    `-w, --watch` watch for changes
    `--v 6` verbose logging

`kubectl get pods --selector='labelName=labelValue'`
    `'!env'`
    `'env'`
    `env in (prod,devel)`
    `env notin (prod,devel)`

`kubectl create`
  `-f, --filename=[]` Filename, directory, or URL to files to use to create the resource
  `--record` record the command

`kubectl delete pods pod_name`
  `--force` force to delete

`kubectl describe node NODE_NAME`

`kubectl cp /path/to/file /target/path`

Deploying your Node.js app: create ReplicationController `kubectl run kubia --image=luksa/kubia --port=8080 --generator=run/v1`
Accessing your web application:  creating a service object `kubectl expose rc kubia --type=LoadBalancer --name kubia-http`
accessing your service through its external ip `curl 104.155.74.57:8080`

`kubectl scale rc kubia --replicas=3` increasing the desired replica count

`kubectl create -f FILE_NAME.yaml` command is used for creating any resource (not only pods) from a YAML or JSON file.
`kubectl apply -f FILE_NAME.yaml` æ›´æ–°
`kubectl edit deploy piggy-mongo` open the YAML definition in your default text editor ä¿®æ”¹
`kubectl patch svc nodeport -p '{"spec":{"externalTrafficPolicy":"Local"}}'` æ·»åŠ 

`docker logs <container id>`
`kubectl logs kubia-manual` retrieving a podâ€™s log with kubectl logs
`kubectl logs kubia-manual -c <container name>` specifying the container name when getting logs of a multi-container pod
    `--previous` figure out why the previous container

`kubectl exec -it <pod name> -- /bin/sh`  è¿›å…¥podå†…éƒ¨
`kubectl port-forward pod-name 8888:8080` forwarding a local network port 8888 to a port 8080 in the pod

`k top node` node èµ„æºä½¿ç”¨æƒ…å†µ
`k top pod` pod èµ„æºä½¿ç”¨æƒ…å†µ
`k top pod --containers` container èµ„æºä½¿ç”¨æƒ…å†µ

COMMUNICATING WITH PODS THROUGH THE API SERVER
`kubectl proxy`
use localhost:8001 rather than the actual API server host and port. Youâ€™ll send a request to the kubia-0 pod like this:
`curl localhost:8001/api/v1/namespaces/default/pods/kubia-0/proxy/`

`kubectl autoscale deployment kubia --cpu-percent=30 --min=1 --max=5` creates the HPA object for you and sets the Deployment called kubia as the scaling target
`kubectl get hpa`
a containerâ€™s CPU utilization is the containerâ€™s actual CPU usage divided by its requested CPU
`kubectl cordon <node>` marks the node as unschedulable (but doesnâ€™t do anything with pods running on that node).
`kubectl drain <node>` marks the node as unschedulable and then evicts all the pods from the node.

### PVC

`kubectl get pvc` volume claim
`kubectl patch pvc test-pvc -p '{"spec":{"resources":{"requests":{"storage":"50Gi"}}}}'` resize pvc

### Pod

`k port-forward pod-name 8001:5000` æœ¬åœ°ç«¯å£ 8001 è½¬å‘åˆ° pod çš„ç«¯å£ 5000

#### [Assign Pods to Nodes](https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/)

`nodeName: foo-node # schedule pod to specific node`

```yaml
nodeSelector:
  svrtype: web

```

### Service

è®¿é—®URI: `SERVICE_NAME.NAMESPACE.svc.cluster.local`
 `svc.cluster.local` is a configurable cluster domain suffix used in all cluster local service names.

[Debug Services](https://kubernetes.io/docs/tasks/debug-application-cluster/debug-service/)

### Deployment

`k rollout history deployment  deployment-name` deployment å†å²è®°å½•
`kubectl set image deployment kubia nodejs=luksa/kubia:v3` Changes the container image defined in a Pod
`kubectl rollout status deployment kubia` the progress of the rollout
`kubectl rollout history deployment kubia` displaying a deploymentâ€™s rollout history
`kubectl rollout undo deployment kubia` undoing a rollout
`kubectl rollout undo deployment kubia --to-revision=1`

deployment strategies:

* RollingUpdate
* Recreate

### Label

`kubectl label pod kubia-manual creation_method=manual` Modifying labels of existing pods
    `--overwrite`
`kubectl get pod -l creation_method=manual` Listing pods using a label selector
`kubectl get pod -l env` To list all pods that include the env label
`kubectl get po -l '!env'` To list all pods that donâ€™t have the env label

### Namespaces

`kubectl create ns name`
`kubectl get ns`
`kubectl get pod --namespace kube-system`

`kubectl config set-context --current --namespace=piggy` change namespace
`alias kcn='kubectl config set-context $(kubectl config current-context) --namespace '`

`kubectl create -f dev.json`

```json
{
  "apiVersion": "v1",
  "kind": "Namespace",
  "metadata": {
    "name": "dev",
    "labels": {
      "name": "dev"
    }
  }
}
```

`kubectl delete ns custom-namespace` delete the whole namespace (the pods will be deleted along with the namespace automatically)
`kubectl delete po --all` Deleting all pods in a namespace, while keeping the namespace
`kubectl delete all --all` Deleting (almost) all resources in a namespace

### ConfigMap

`kubectl create configmap fortune-config --from-literal=sleep-interval=2 --from-literal=foo=bar --from-literal=bar=baz`
`kubectl create -f fortune-config.yaml`
`kubectl create configmap my-config --from-file=config-file.conf`
`kubectl create configmap my-config --from-file=/path/to/dir`

PATCH `kubectl patch configmap tcp-services --type merge -p '{"data":{"5672": "rabbitmq-system/rabbitmqcluster:5672"}}'`

CREATING A TLS CERTIFICATE FOR THE INGRESS
`kubectl create secret tls tls-secret --cert=tls.cert --key=tls.key`
`kubectl create secret generic fortune-https --from-file=https.key --from-file=https.cert --from-file=foo`

`exec` formâ€”For example, `ENTRYPOINT ["node", "app.js"]`: runs the node process directly (not inside a shell)
`shell` formâ€”For example, `ENTRYPOINT node app.js`: used the shell form

### System

`kubectl get events` æŸ¥çœ‹ç›¸å…³äº‹ä»¶

### [Managing Resources for Containers](https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/)

**request**: the scheduler uses this information to decide which node to place the Pod on. The kubelet also reserves at least the request amount of that system resource specifically for that container to use.  It is default to the limits if requests is not set explicitly.
**limit**: the kubelet enforces those limits so that the running container is not allowed to use more of that resource than the limit you set

#### Exceeding the limits

CPU: when a CPU limit is set for a container, the process isnâ€™t given more CPU time than the config- ured limit.
Memory: When a process tries to allocate memory over its limit, the process is killed (itâ€™s said the container is OOMKilled, where OOM stands for Out Of Memory)

#### pod QoS classes

* BestEffort (the lowest priority)
  1. Itâ€™s assigned to pods that donâ€™t have any requests or limits set at all (in any of their containers)
  2. They will be the first ones killed when memory needs to be freed for other pods.
* Burstable
  In between BestEffort and Guaranteed is the Burstable QoS class. All other pods fall into this class
  When two single-container pods exist, both in the Burstable class, the system will kill the one using more of its requested memory than the other, percentage-wise
* Guaranteed (the highest)
  1. Requests and limits need to be set for both CPU and memory.
  2. They need to be set for each container.
  3. They need to be equal (the limit needs to match the request for each resource in each container).

##### which process gets killed when memory is low

First in line to get killed are pods in the BestEffort class, followed by Burstable pods, and finally Guaranteed pods, which only get killed if system processes need memory.

### Advanced Scheduling

`kubectl taint node node1.k8s node-type=production:NoSchedule` adds a taint with key node-type, value production and the NoSchedule

Three possible effects exist:

* `NoSchedule`, which means pods wonâ€™t be scheduled to the node if they donâ€™t tol- erate the taint.
* `PreferNoSchedule` is a soft version of NoSchedule, meaning the scheduler will try to avoid scheduling the pod to the node, but will schedule it to the node if it canâ€™t schedule it somewhere else.
* `NoExecute`, unlike NoSchedule and PreferNoSchedule that only affect schedul- ing, also affects pods already running on the node. If you add a NoExecute taint to a node, pods that are already running on that node and donâ€™t tolerate the NoExecute taint will be evicted from the node.

### Deploy process

1. build image `docker build -t registry.cn-beijing.aliyuncs.com/namespace/image-name:image-version . -f deploy/Dockerfile`
2. å°†é•œåƒæ¨é€åˆ°Registry `docker push`
3. å¯åŠ¨ pod `kubectl run pod-name -n namespace --image=registry.cn-beijing.aliyuncs.com/namespace/image-name:image-version -it --rm --restart=Never -- bash`

### Managing podsâ€™ computational resources

* BestEffort (the lowest priority)
* Burstable
* Guaranteed (the highest)

#### Jenkins

[Kubernetes CLI](https://plugins.jenkins.io/kubernetes-cli/) éƒ¨ç½²å¤šä¸ªé›†ç¾¤

```groovy
withKubeConfig([credentialsId: 'k8s_config_prd'
                    ]) {
                  sh "kubectl config view"
                  sh "kubectl get pods"
                }
```

### Network

[ä»é›¶å¼€å§‹å…¥é—¨ K8s | ç†è§£ CNI å’Œ CNI æ’ä»¶](https://developer.aliyun.com/article/748866)
[kubernetesç½‘ç»œæ¨¡å‹ä¹‹â€œå°è€Œç¾â€flannel](https://zhuanlan.zhihu.com/p/79270447)

Kubernetes å¯¹é›†ç¾¤ç½‘ç»œæœ‰ä»¥ä¸‹è¦æ±‚ï¼š
æ‰€æœ‰çš„ Pod ä¹‹é—´å¯ä»¥åœ¨ä¸ä½¿ç”¨ NAT ç½‘ç»œåœ°å€è½¬æ¢çš„æƒ…å†µä¸‹ç›¸äº’é€šä¿¡ï¼›æ‰€æœ‰çš„ Node ä¹‹é—´å¯ä»¥åœ¨ä¸ä½¿ç”¨ NAT ç½‘ç»œåœ°å€è½¬æ¢çš„æƒ…å†µä¸‹ç›¸äº’é€šä¿¡ï¼›æ¯ä¸ª Pod çœ‹åˆ°çš„è‡ªå·±çš„ IP å’Œå…¶ä»– Pod çœ‹åˆ°çš„ä¸€è‡´ã€‚

#### Kubernetes CNI

CNIï¼Œå®ƒçš„å…¨ç§°æ˜¯ Container Network Interfaceï¼Œå³å®¹å™¨ç½‘ç»œçš„ API æ¥å£ã€‚

å®ƒæ˜¯ K8s ä¸­æ ‡å‡†çš„ä¸€ä¸ªè°ƒç”¨ç½‘ç»œå®ç°çš„æ¥å£ã€‚Kubelet é€šè¿‡è¿™ä¸ªæ ‡å‡†çš„ API æ¥è°ƒç”¨ä¸åŒçš„ç½‘ç»œæ’ä»¶ä»¥å®ç°ä¸åŒçš„ç½‘ç»œé…ç½®æ–¹å¼ï¼Œå®ç°äº†è¿™ä¸ªæ¥å£çš„å°±æ˜¯ CNI æ’ä»¶ï¼Œå®ƒå®ç°äº†ä¸€ç³»åˆ—çš„ CNI API æ¥å£ã€‚å¸¸è§çš„ CNI æ’ä»¶åŒ…æ‹¬ Calicoã€flannelã€Terwayã€Weave Net ä»¥åŠ Contivã€‚

æ’ä»¶è´Ÿè´£ä¸ºæ¥å£é…ç½®å’Œç®¡ç†IPåœ°å€ï¼Œå¹¶ä¸”é€šå¸¸æä¾›ä¸IPç®¡ç†ã€æ¯ä¸ªå®¹å™¨çš„IPåˆ†é…ã€ä»¥åŠå¤šä¸»æœºè¿æ¥ç›¸å…³çš„åŠŸèƒ½ã€‚å®¹å™¨è¿è¡Œæ—¶ä¼šè°ƒç”¨ç½‘ç»œæ’ä»¶ï¼Œä»è€Œåœ¨å®¹å™¨å¯åŠ¨æ—¶åˆ†é…IPåœ°å€å¹¶é…ç½®ç½‘ç»œï¼Œå¹¶åœ¨åˆ é™¤å®¹å™¨æ—¶å†æ¬¡è°ƒç”¨å®ƒä»¥æ¸…ç†è¿™äº›èµ„æºã€‚

K8s é€šè¿‡ CNI é…ç½®æ–‡ä»¶æ¥å†³å®šä½¿ç”¨ä»€ä¹ˆ CNIã€‚åŸºæœ¬çš„ä½¿ç”¨æ–¹æ³•ä¸ºï¼š

1. é¦–å…ˆåœ¨æ¯ä¸ªç»“ç‚¹ä¸Šé…ç½® CNI é…ç½®æ–‡ä»¶(/etc/cni/net.d/xxnet.conf)ï¼Œå…¶ä¸­ xxnet.conf æ˜¯æŸä¸€ä¸ªç½‘ç»œé…ç½®æ–‡ä»¶çš„åç§°ï¼›
2. å®‰è£… CNI é…ç½®æ–‡ä»¶ä¸­æ‰€å¯¹åº”çš„äºŒè¿›åˆ¶æ’ä»¶ï¼›
3. åœ¨è¿™ä¸ªèŠ‚ç‚¹ä¸Šåˆ›å»º Pod ä¹‹åï¼ŒKubelet å°±ä¼šæ ¹æ® CNI é…ç½®æ–‡ä»¶æ‰§è¡Œå‰ä¸¤æ­¥æ‰€å®‰è£…çš„ CNI æ’ä»¶ï¼›
4. ä¸Šæ­¥æ‰§è¡Œå®Œä¹‹åï¼ŒPod çš„ç½‘ç»œå°±é…ç½®å®Œæˆäº†ã€‚

#### é˜¿é‡Œäº‘Kubernetesæ‰˜ç®¡ç‰ˆå¼€å¯ hairpin æ¨¡å¼

æ®å®¢æœå›å¤ç›®å‰(2020-11-20)æ²¡æœ‰ç®€å•çš„é…ç½®æ–¹å¼, ä½†å‘ç°ä¸‹é¢çš„æ–¹å¼æš‚æ—¶æœ‰æ•ˆæœ:

1. ç¡®è®¤ç½‘ç»œæ’ä»¶ç±»å‹æ˜¯ csi
`ps aux | grep kubelet | grep /usr/bin/kubelet | grep network-plugin`

2. æ‰¾åˆ°é…ç½®æ–‡ä»¶ä½ç½® `ls /etc/cni/net.d/*flannel.conf`
åœ¨æ¯å° node æœºå™¨ä¸Šçš„é…ç½®æ–‡ä»¶ /etc/cni/net.d/10-flannel.conf å¢åŠ   "hairpinMode": true

```yaml
{
  "name": "cb0",
  "cniVersion":"0.3.0",
  "type": "flannel",
  "delegate": {
    # "hairpinMode": true,
    "isDefaultGateway": true
  }
}
```

## Useful image

`kubectl run mysql-client --image=mysql:5.6 -it --rm --restart=Never -- mysql`
`kubectl run redis-client --image=redis:6.0.9 -it --rm --restart=Never -- bash`
`kubectl run dnsutils --image=tutum/dnsutils -it --rm`
`kubectl run -it srvlookup --image=tutum/dnsutils --rm --restart=Never -- dig SRV kubia.default.svc.cluster.local`
`kubectl run -it curl --image=tutum/curl --rm --restart=Never`
`kubectl run nginx --image=nginx -it --rm`
`kubectl run busybox --image=busybox -it --rm`  busybox: BusyBox combines tiny versions of many common UNIX utilities
`kubectl run alpine --image=alpine -it --rm`  alpine: A minimal Docker image based on Alpine Linux
  `apk add curl` install curl

## helm

`helm repo add ali-incubator https://aliacs-app-catalog.oss-cn-hangzhou.aliyuncs.com/charts-incubator/`
`helm repo add ali-stable https://kubernetes.oss-cn-hangzhou.aliyuncs.com/charts`
helm search repo gitlab-ce
helm fetch ali-stable/gitlab-ce
helm uninstall gitlab

## Setup

[Supercharge your Kubernetes setup with OhMyZSH ğŸš€ğŸš€ğŸš€ + awesome command line tools](https://agrimprasad.com/post/supercharge-kubernetes-setup/)
[kube-ps1](https://github.com/jonmosco/kube-ps1)
`brew install kube-ps1`
kube-shell `pip install kube-shell --user -U`
`brew install kubectx`
åˆ‡æ¢é›†ç¾¤ç”¨çš„å‘½ä»¤ [kubectx + kubens: Power tools for kubectl](https://github.com/ahmetb/kubectx)
[Krew is a tool that makes it easy to use kubectl plugins](https://krew.sigs.k8s.io/docs/user-guide/setup/install/)

ç»ˆæå·¥å…·k9s

## Best Practice

### å£°æ˜æ¯ä¸ªPodçš„resource

[é«˜å¯é æ¨èé…ç½®](https://help.aliyun.com/document_detail/128157.html)
Kubernetesé‡‡ç”¨é™æ€èµ„æºè°ƒåº¦æ–¹å¼ï¼Œå¯¹äºæ¯ä¸ªèŠ‚ç‚¹ä¸Šçš„å‰©ä½™èµ„æºï¼Œå®ƒæ˜¯è¿™æ ·è®¡ç®—çš„ï¼šèŠ‚ç‚¹å‰©ä½™èµ„æº=èŠ‚ç‚¹æ€»èµ„æº-å·²ç»åˆ†é…å‡ºå»çš„èµ„æºï¼Œå¹¶ä¸æ˜¯å®é™…ä½¿ç”¨çš„èµ„æºã€‚å¦‚æœæ‚¨è‡ªå·±æ‰‹åŠ¨è¿è¡Œä¸€ä¸ªå¾ˆè€—èµ„æºçš„ç¨‹åºï¼ŒKuberneteså¹¶ä¸èƒ½æ„ŸçŸ¥åˆ°ã€‚

å¦å¤–æ‰€æœ‰Podä¸Šéƒ½è¦å£°æ˜resourcesã€‚å¯¹äºæ²¡æœ‰å£°æ˜resourcesçš„Podï¼Œå®ƒè¢«è°ƒåº¦åˆ°æŸä¸ªèŠ‚ç‚¹åï¼ŒKubernetesä¹Ÿä¸ä¼šåœ¨å¯¹åº”èŠ‚ç‚¹ä¸Šæ‰£æ‰è¿™ä¸ªPodä½¿ç”¨çš„èµ„æºã€‚å¯èƒ½ä¼šå¯¼è‡´èŠ‚ç‚¹ä¸Šè°ƒåº¦è¿‡å»å¤ªå¤šçš„Podã€‚

## Example

### æš´éœ² TCP æœåŠ¡

#### service type = CluserIP é€šè¿‡Ingress

é˜¿é‡Œäº‘ kubernetes é…ç½®

1. é…ç½® configmap: å®¹å™¨æœåŠ¡ -> åº”ç”¨é…ç½®-> é…ç½®é¡¹ -> tcp-services -> æ·»åŠ  åç§°: config-name, å€¼: namespace/serviceName:service port, æ³¨æ„åç§°config-name éœ€è¦é…ç½®åˆ° ingress å®¹å™¨ç«¯å£, ä¾‹å¦‚ 22:kube-ops/gitlab:22
2. é…ç½® service: å®¹å™¨æœåŠ¡ -> è·¯ç”±ä¸è´Ÿè½½å‡è¡¡ -> æœåŠ¡ -> nginx-ingress-lb -> æ›´æ–° å¢åŠ ç«¯å£
   port æ˜¯æš´éœ²çš„å…¬ç½‘ç«¯å£(æ§åˆ¶å°å«åš æœåŠ¡ç«¯å£), targetPort æ˜¯ configmap åç§° (æ§åˆ¶å°å«åš å®¹å™¨ç«¯å£), è¿™é‡Œå®¹å™¨ç«¯å£åªèƒ½æ˜¯æ•°å­—, æ‰€ä»¥åè¿‡æ¥é™åˆ¶ç¬¬ä¸€æ­¥çš„ config-name åªèƒ½ç”¨æ•°å­—

ç„¶å ingress ä¼šåŠ¨æ€è¯»å–tcp-services æš´éœ²ç«¯å£
tcp-services-configmap=$(POD_NAMESPACE)/tcp-services

`kubectl patch configmap tcp-services --type merge -p '{"data":{"5672": "rabbitmq-system/rabbitmqcluster:5672"}}'`

reference:
[ç©è½¬Kubernetes TCP Ingress](https://developer.aliyun.com/article/603225)
[Exposing TCP and UDP services](https://kubernetes.github.io/ingress-nginx/user-guide/exposing-tcp-udp-services)

#### service type = NodePort

1. åœ¨è´Ÿè½½å‡è¡¡è®¾ç½®ç«¯å£æ˜ å°„, ç›‘å¬è™šæ‹ŸæœåŠ¡å™¨ç»„çš„ç«¯å£è®¾ç½®ä¸º NodePort 30022
2. å®‰å…¨ç»„æ”¾å¼€ nodePort 30022
