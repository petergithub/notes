# 研发员工指南-流程篇 原则篇

[郑昀 老兵笔记](https://mp.weixin.qq.com/s?__biz=MzA4ODM0OTc0NQ==&mid=2650915337&idx=1&sn=80caf13b896bf05512b7eabd702fd319&chksm=8bdeef57bca96641558e3ad22cc73443029477a7cda65ca1c7ef4df6566f366ea8fec2d53087&scene=132#wechat_redirect)

## 1.前言

流程大致可分为以下五类：

1.运维类

2.硬件类

3.软件类

4.配置管理类

5.数据类

## 2.流程篇

### 2.1运维类流程

讲运维流程之前，我们先定义一下线上业务故障和事故的级别：

* P0：核心业务重要功能不可用且大面积影响用户。响应时间：立即
* P1：核心业务重要功能不可用，但影响用户有限，如仅影响内部用户。响应时间：小于15分钟
* P2：核心业务周边功能不可用，持续故障将大面积影响用户体验。响应时间：小于15分钟
* P3：周边业务功能不可用，轻微影响用户体验。响应时间：小于4小时
* P4：周边业务功能不可用，但基本不影响用户正常使用。响应时间：小于6小时

很快我们就会用到这个故障级别。

#### 2.1.1故障处理善后流程

修完BUG之后，还有三件事需要做：

1.评估影响范围并纠正

2.撰写RCA报告并通报

3.举一反三防范风险

#### 2.1.2 开源软件定期更新机制流程

#### 2.1.3 核心业务上线观察机制

经常维护核心业务的老兵都知道，系统发布之后，不经历几个交易周期的波峰波谷，真不敢说发布成功。经历过多次磨难之后，我们定义了这样的观察机制：

发布时机的选择

灰度发布 小心求证

发布后观察窗口

重大变更间隔发布

### 2.3 软件类流程

软件其实包罗万象，前后端开发，小程序开发，APP客户端开发，太通用的流程我们就不讲了。

#### 2.3.1数据库访问帐号的申请和审批流程

测试环境和生产环境的数据库，统一由数据库管理员也就是DBA管理，开发员工没有权限操作；

DBA管理数据库的重要工具之一就是我们自研的iDB。

第一条，从技术上杜绝所有研发同学直连MySQL/MyCat的可能性：
堵住技术人员在没有任何监管的情况下直接查生产数据库（含私有云和公有云）的同时，必须给他们一条通路，那就是：第一，用 iDB，第二，用数据开放实验室。iDB的线上数据查询功能，本来也有拦截高危SQL的能力。
第二条，从技术上杜绝所有工程（包括PHP）配置文件里写明文密码的可能性：

#### 2.3.2 核心交易流程定期压力测试流程

除了接口压测之外，还有一种全链路压测，它适用于这种场景：第一，针对链路长、环节多、服务依赖复杂的系统，全链路压测可以更快更准确地定位问题；第二，系统必须有完备的监控报警，在压测出现问题的时候可以随时终止操作；第三，有明显的业务峰值和低谷。比如说美团采用自主开发的pTest压测工具对核心交易做全链路压测。

在全链路压测的研究中，业界基本形成了四种解决方案：

第一种是基于TCP/HTTP流量录制和回放，如网易的tcpcopy，twitter的diffy，都是在应用外部基于网络层实现流量的录制、回放和倍数放大。

第二种是基于Java AOP录制和回放，在Java应用内通过AOP切面编程方式实现的流量录制和回放，并且有Mock机制，可实现写流量的回归验证。阿里早年间有一个DOOM，后来它被放入阿里云的云效里，这是一个收费项目。据称阿里内部几乎所有交易核心系统都通过DOOM去做引流回归测试。

第三种是基于接口和预置CSV数据，典型代表是阿里云的PTS和ARMS（Application Real-Time Monitoring Service）服务。PTS+ARMS就是个JMeter注4在线豪华版，所以JMeter脚本可以转为PTS脚本。

第四种是基于RPC调用录制和回放，如滴滴的RDebug。

毋庸讳言，核心交易流程更新频繁，如果不定期做一次体检，早晚会出事，而且一出事就是大事。压测应由达摩院质量控制部发起，各个业务产研团队必须通力配合。

大家要注意做压测的初心，做压测方案的时候别跑偏了。压测的目的有四条：

第一条，了解现状，得到现有应用方案在一个或多个特定配置下的性能基准值。

第二条，性能调优，根据压测，必然能够暴露很多问题，比如我们认为怎么着也得压到1000 QPS吧，但实际上压到500 QPS服务就爆掉了，那就得调优了。

第三个，把握未来，根据基准定期观察新版本的性能是上升了还是下降了，所以几个大版本发布之后必须再安排一次压测。

第四个，容量预估，交易笔数翻一倍怎么扩容，翻两倍怎么扩，不能拍脑袋。

### 2.4配置管理类流程

#### 2.4.1 日常代码分支管理流程规范

严禁开发同学私自上传项目代码到公有的代码托管平台上

#### 2.4.1.2 分支管理

为了减轻开发人员拉取和合并分支的压力，常用分支只维护以下四个：

开发分支（Feature）

测试分支（Release）

上线分支（Release-online）

稳定分支（Master）

Release分支上线后，对应的功能验证通过，再经过一天业务高峰低谷的运行，确认无问题后，将Release-online分支合并到Master分支。

## 5.原则篇

### 5.1运维原则

#### 5.1.1核心业务高级别故障处理口诀

口诀：遇事不乱，分头核查，群里同步，简单陈述，绝不恋战，恢复服务。

分头核查：质量控制部负责人要争取复现现象，确认问题是否存在；运维部负责人核查业务对应的机房、数据库、内外网流量、应用负载是否正常。

绝不恋战：如果迟迟定位不了问题（比如五分钟之内），就不可恋战，必须快速恢复业务，如利用异地双活系统切换流量。切记：第一，不要把生产环境当成测试环境，不要在线调试，第二，不要一直留着现场观察来观察去。

#### 5.1.2严重BUG不过夜

#### 5.1.3永远的后备方案

我们必须准备一个后备方案，比如在这些场景：

大版本上线和数据迁移

升级第三方服务

保护数据安全

#### 5.1.4竭尽可能消灭Exception和慢查

引入ELK，在此基础上开发了每日异常分析汇总邮件。从那以后，每新增一种异常日志，我们就能立即发现

### 5.2设计原则

#### 5.2.1设计原则先行

每一位设计师都需要知道这个常识：

当你开始构建或重构一个复杂系统的时候，请先把大的设计原则写下来，然后在这些设计原则的框架内做推演。

阿里巴巴资深技术专家毕玄这样总结自己的系统设计方法：回顾了自己做过的几个系统的设计，发现自己在做系统设计的时候确实是会按照一个套路去做，这个套路就是：

系统设计的目的->系统设计的目标->围绕目标的核心设计->围绕核心设计形成的设计原则->各子系统和模块的详细设计。

（一）系统设计的目的

指的是做这个系统设计的目的到底是什么。很多人在做系统设计时，搞不清为什么要做一个新系统的设计，或者为什么要做一个系统的重构/演进的设计。如果搞不清楚这个目的，后面的系统设计上很容易形成偏差，导致本来是为了解决一个问题，才去做的重构或升级，但最后完全脱离了初心。

另外，还有一点很重要，一个大架构师是需要给很多人讲解系统设计的，只有理解并讲清了系统设计的目的，团队才能更好的去实现。

（二）系统设计的目标

围绕上面的目的，能不能形成一些可衡量的目标，从而确保最终系统实现和最初的目的不要出现太大的偏差。相信很多人都经历过最终的系统实现和系统设计偏差极大的现象，主要的原因基本都是没有制定衡量系统设计的目标，并在系统设计上让系统能透出这些目标。

（三）围绕目标的核心设计

这一步最重要的就是通过设计如何去实现上面的目标。这个环节中技术的专业、视野、全面的考虑、权衡取舍的主观原则、解题的思路，是形成核心设计的关键。

在核心设计的这个阶段中，会产生一些新的目标，可以衡量设计的最后实现情况，这些也都要追加到系统设计中，确保最后的实现和设计的偏差度是可视的。

（四）围绕核心设计形成的设计原则

有了上面的核心设计后，可以真正地形成一些设计原则，确保后面的子系统和模块的详细设计中能够遵循，并在详细设计中体现出来，这样才能保证整个大的系统设计的一致性。

（五）各子系统和模块的详细设计

到了这个时候，难度不会太大，毕竟有了前面的铺垫，只是解好一个更小范围的题目而已，程序员群体在解题能力上通常是不错的。

#### 5.2.2关键数据历史可追溯

历史不得直接篡改和历史可追溯是一对，一个问题的两面。

（一）历史不得直接篡改
这里的“直接修改”特指，没有把变更行为记录到日志表里，而是直接在原始记录上update甚至delete。这种“毁尸灭迹”是明文禁止的，即使留下了文件类型日志也是不允许的。我们应该这么做：

第一，要修改这些记录的关键字段时，必须在数据库相关日志表里保留变更日志，并记录操作人和发起人，一定要确保历史可回溯。

第二，严禁对核心关键记录做物理删除，只能是软删除。

（二）历史可追溯
系统对关键记录做了一系列修改，甚至有程序在某个时间段内误写引入了脏数据，我们必须能从各种操作日志表中随时倒推回历史某一个时刻的快照，一是确保随时能安全地把数据还原回去，二是管理平台可以清晰地展示出由谁引发、怎么变化的历史，三是便于排查问题。

#### 5.2.3 系统高可用原则

商业系统上线的时候，必须是监控告警配置到位，必须是高可用的，不允许引入单点风险。

#### 5.2.4 不拿生产环境做试验

#### 5.2.5 数据补偿原则

我们能看到不管是哪一家的关键业务，都是围绕着一个核心系统，一层一层叠加各种自动化规则，叠加各种数据补偿定时任务，一层补丁摞一层补丁，以此确保服务的高可靠性。

举个例子，设计之初就要建立校验订单交易数据一致性的定时任务，比如以数据库操作日志为依据，挨个校验单个订单、交易流水的各项数据是否一致，如果发现不一致，第一要告警，第二尽量自动修复，比如说原路退返。这也是设计评审的一个重要考察环节。

#### 5.2.6 接入异地双活原则

#### 5.2.7 谨慎使用updatetime作为更新依据

#### 5.2.8 数据库设计和变更提前与DBA沟通

工程师切勿自行其事。请提前与专业人士沟通。

举几个例子：

大表（如订单表）上需要预留足够多（如10个）扩展字段，后期复用时改字段名即可，不影响业务，无需停服。

大表真的被迫加字段的话，请提前一天加好，千万不要与上线动作绑在一起。大表加字段，请选择凌晨执行，因为以5G的数据量为例可能耗时10分钟左右，对业务有致命影响。

异地双活里，对于双活数据库而言，有主机房概念，如果先在主机房的双活数据库上做表结构变更，会导致otter同步中断，所以请先变更从机房的双活数据库的表结构，然后再变更主机房的。

#### 5.2.9 重构的两个“有利于”原则

我在意的是两个“是否有利于”：

一，是否有利于发布部署；

二，是否有利于排除故障（是否有利于快速定位线上问题和解决问题）。

随着业务规模越来越大，随着应用越来越多，随着容器化，随着前后端分离导致内部接口越来越多，随着 API 网关的引入，我们越来越难以在5分钟之内断定系统出了什么事儿。因此，我要求：

原则一：凡是中间件，不管是自主研发的，还是以开源软件为内核构建出来的，都必须自带监控报警，否则不允许上线。

原则二：本着 Don't make me think的哲学思路，所有对排除故障有帮助的信息，都必须一站式可视化展示。

可以说我们打造的每一个系统都体现了这两个原则。

不需要东奔西走四处收集蛛丝马迹。

不需要一次性点开几百个指标页面，脑补推演。

不需要精通集群部署结构。

不需要熟知应用日志的路径。
